{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second architecture: Bottleneck Features (InceptionV3) + Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from livelossplot import PlotLossesKeras\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#windows path\n",
    "DATASET_DIR = \" \" # path to dataset's folder\n",
    "TRAIN_DIR = DATASET_DIR+\"\\\\train\"# path to training set's folder\n",
    "TEST_DIR = DATASET_DIR+\"\\\\test\"# path to test set's folder\n",
    "\n",
    "TRAIN_LABEL = DATASET_DIR+\"\\\\labels.csv\" # path to label set's folder\n",
    "TRAIN_SET_DIR = DATASET_DIR+\"\\\\train_set\"# path to traning set's folder [pre-processed]\n",
    "VAL_SET_DIR = DATASET_DIR+\"\\\\val_set\"# path to validation set's folder [pre-processed]\n",
    "TEST_SET_DIR = DATASET_DIR+\"\\\\test_set\"# path to test set's folder [pre-processed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hot_enconding(ypred, n_classes):\n",
    "    hot_encoder = np.zeros(shape=(ypred.shape[0], n_classes))\n",
    "    for i in range(ypred.shape[0]):\n",
    "        hot_encoder[i][int(ypred[i])] = 1\n",
    "    return hot_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(DIR, n_total_images, n_features, size_img, conv):\n",
    "    i = 0\n",
    "    label = 0\n",
    "    features = np.zeros(shape=(n_total_images, n_features))\n",
    "    labels = np.zeros(shape=(n_total_images, 1))\n",
    "    for root, dirs, files in os.walk(DIR):\n",
    "        for dirname in tqdm(sorted(dirs)):\n",
    "            filelist = os.listdir(DIR+'\\\\'+dirname)\n",
    "            filelist = np.asarray(filelist)\n",
    "            for filename in filelist:\n",
    "                img_path = DIR+'\\\\'+dirname+'\\\\'+filename\n",
    "                img = image.load_img(img_path, target_size=(size_img, size_img))\n",
    "                \n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)#normalize[-1,1]\n",
    "                \n",
    "                features[i,:] = conv.predict(x)\n",
    "                labels[i] = label\n",
    "                i = i+1\n",
    "            label = label+1       \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_single_feature(img_path, n_features, size_img, conv):\n",
    "\n",
    "    features = np.zeros(shape=(1, n_features))\n",
    "    img = image.load_img(img_path, target_size=(size_img, size_img))\n",
    "                \n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "                \n",
    "    features[0,:] = conv.predict(x)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_single_feature_image(img, n_features, conv):\n",
    "    \n",
    "    features = np.zeros(shape=(1, n_features))\n",
    "\n",
    "    x = np.expand_dims(img, axis=0)               \n",
    "    features[0,:] = conv.predict(x)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probability2discreteOutput(ypred):\n",
    "    y_pred_d = []\n",
    "    for i in range(ypred.shape[0]):\n",
    "        y_pred_d.append(np.argmax(ypred[i]))\n",
    "    y_pred_d = np.asarray(y_pred_d)\n",
    "    return y_pred_d.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading breeds from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_LABEL)\n",
    "breeds = df_train.breed.unique()\n",
    "breeds = np.sort(breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck Features (InceptionV3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_img = 300\n",
    "conv_model = InceptionV3(include_top = False, weights='imagenet', input_shape=(size_img, size_img, 3), pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 2048\n",
    "train_features, train_labels = extract_features(TRAIN_SET_DIR, 6547, n_features, size_img, conv_model)\n",
    "val_features, val_labels = extract_features(VAL_SET_DIR, 1580, n_features, size_img, conv_model)\n",
    "test_features, test_labels = extract_features(TEST_SET_DIR, 2095 , n_features, size_img, conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_features.shape, train_labels.shape)\n",
    "print(train_features.shape, train_labels.shape)\n",
    "\n",
    "stackfeatures =  np.vstack((train_features, val_features))\n",
    "stacklabel =  np.vstack((train_labels, val_labels))\n",
    "stacklabel = stacklabel.reshape(train_labels.shape[0]+val_labels.shape[0])\n",
    "print(stackfeatures.shape, stacklabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', n_jobs=2)\n",
    "logreg.fit(stackfeatures, stacklabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = logreg.predict_proba(test_features)\n",
    "ypred = probability2discreteOutput(pred)#converting output to discrete label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation: accuracy, error (log loss), and f1-score (average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 120\n",
    "encoded_pred = hot_enconding(ypred, n_classes)\n",
    "encoded_true = hot_enconding(test_labels, n_classes)\n",
    "acc = accuracy_score(test_labels, ypred)\n",
    "loss = log_loss(encoded_true, pred, eps=1e-15)\n",
    "f1_sc = f1_score(test_labels, ypred, average='micro')\n",
    "print(\"acc:\",acc,\"error:\",loss,\"f1-score:\",f1_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "TEST_SET_DIR,target_size=(300, 300),\n",
    "batch_size=batch_size,\n",
    "class_mode='categorical')\n",
    "batch_elem = test_generator.next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_breeds = dict(zip(breeds, range(breeds.shape[0])))\n",
    "data_batch = batch_elem[0]\n",
    "labels_batch = batch_elem[1]\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "#from https://matplotlib.org/2.0.2/mpl_toolkits/axes_grid/users/overview.html\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 5),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.04,  # pad between axes in inch.\n",
    "                 )\n",
    "font = {'family': 'serif',\n",
    "        'size': 12,\n",
    "        }\n",
    "for i in range(10):\n",
    "    ax = grid[i]\n",
    "    data = np.copy(data_batch[i])\n",
    "    label = labels_batch[i]\n",
    "    label_breed = np.argmax(label)\n",
    "    #print(np.max(data),np.min(data))\n",
    "    #x = np.expand_dims(data, axis=0)\n",
    "    \n",
    "    #feature = conv_model.predict(x)\n",
    "    img = np.copy(data)\n",
    "    feature = extract_single_feature_image(img, n_features, conv_model)\n",
    "    \n",
    "    pred = logreg.predict_proba(feature)\n",
    "    label_pred = np.argmax(pred)\n",
    "\n",
    "    ax.text(10, 250, 'Label: %s' % (breeds[label_breed]),  fontdict=font, color='b', backgroundcolor='w', alpha=0.8)\n",
    "    ax.text(10, 280, 'Pred: %s (%.2f)' % (breeds[label_pred], pred[0][label_pred]),  fontdict=font, color='r', backgroundcolor='w', alpha=0.8)\n",
    "    ax.imshow(data)\n",
    "    ax.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Wrong Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_img = 300\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 5),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.04,  # pad between axes in inch.\n",
    "                 )\n",
    "font = {'family': 'serif',\n",
    "        'size': 14,\n",
    "        }\n",
    "ind = 0\n",
    "for root, dirs, files in os.walk(VAL_SET_DIR):\n",
    "        for dirname in dirs:\n",
    "            filelist = os.listdir(VAL_SET_DIR+'\\\\'+dirname)\n",
    "            filelist = np.asarray(filelist)\n",
    "            for filename in filelist:\n",
    "                if ind == 10:\n",
    "                    break\n",
    "                img_path = VAL_SET_DIR+'\\\\'+dirname+'\\\\'+filename\n",
    "                img = image.load_img(img_path, target_size=(size_img, size_img))\n",
    "                \n",
    "                feature = extract_single_feature(img_path, n_features, size_img, conv_model)\n",
    "              \n",
    "                pred = logreg.predict_proba(feature)\n",
    "                label_pred = np.argmax(pred)\n",
    "                \n",
    "                if breeds[label_pred] != dirname:\n",
    "                    ax = grid[ind]\n",
    "                    #print(img_path)\n",
    "                    ax.text(10, 250, 'Label: %s' % dirname,  fontdict=font, color='b', backgroundcolor='w', alpha=0.8)\n",
    "                    ax.text(10, 280, 'Pred: %s' % (breeds[label_pred]),  fontdict=font, color='r', backgroundcolor='w', alpha=0.8)\n",
    "                    ax.imshow(img)\n",
    "                    ind = ind+1\n",
    "                    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypred = np.zeros([10357,120])\n",
    "filelist = os.listdir(TEST_DIR)\n",
    "filelist = np.asarray(filelist)\n",
    "i = 0\n",
    "diff = 0\n",
    "size_img = 300\n",
    "for filename in tqdm(filelist):\n",
    "    img_path = TEST_DIR+'\\\\'+filename\n",
    "    feat = extract_single_feature(img_path, n_features, size_img, conv_model)\n",
    "\n",
    "    pred = logreg.predict_proba(feat)\n",
    "    ypred[i,:] = pred\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "for i in range(filelist.shape[0]):\n",
    "    name = filelist[i]\n",
    "    name = name[:len(name)-4]\n",
    "    ids.append(name)\n",
    "ids = np.asarray(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(ypred, columns = breeds)\n",
    "df_sub.insert(0, 'id', ids)\n",
    "df_sub.to_csv('architecture2.csv', index=False)\n",
    "print (df_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
