{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First architecture: Transfer learning + data augmentation (InceptionV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from livelossplot import PlotLossesKeras\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#windows path\n",
    "DATASET_DIR = \" \" # path to dataset's folder\n",
    "TRAIN_DIR = DATASET_DIR+\"\\\\train\"# path to training set's folder\n",
    "TEST_DIR = DATASET_DIR+\"\\\\test\"# path to test set's folder\n",
    "\n",
    "TRAIN_LABEL = DATASET_DIR+\"\\\\labels.csv\" # path to label set's folder\n",
    "TRAIN_SET_DIR = DATASET_DIR+\"\\\\train_set\"# path to traning set's folder [pre-processed]\n",
    "VAL_SET_DIR = DATASET_DIR+\"\\\\val_set\"# path to validation set's folder [pre-processed]\n",
    "TEST_SET_DIR = DATASET_DIR+\"\\\\test_set\"# path to test set's folder [pre-processed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hot_enconding(ypred, n_classes):\n",
    "    hot_encoder = np.zeros(shape=(ypred.shape[0], n_classes))\n",
    "    for i in range(ypred.shape[0]):\n",
    "        hot_encoder[i][int(ypred[i])] = 1\n",
    "    return hot_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_images(DIR, n_total_images, size_img):\n",
    "    i = 0\n",
    "    label = 0\n",
    "    features = np.zeros(shape=(n_total_images, size_img*size_img*3))\n",
    "    labels = np.zeros(shape=(n_total_images, 1))\n",
    "    for root, dirs, files in os.walk(DIR):\n",
    "        for dirname in tqdm(sorted(dirs)):\n",
    "            filelist = os.listdir(DIR+'\\\\'+dirname)\n",
    "            filelist = np.asarray(filelist)\n",
    "            for filename in filelist:\n",
    "                img_path = DIR+'\\\\'+dirname+'\\\\'+filename\n",
    "                \n",
    "                img = image.load_img(img_path, target_size=(size_img, size_img))\n",
    "                x = image.img_to_array(img)\n",
    "                x = preprocess_input(x)#normalize[-1,1]\n",
    "\n",
    "                features[i,:] = x.reshape(1,size_img*size_img*3)\n",
    "                labels[i] = label\n",
    "                \n",
    "                i = i+1\n",
    "            label = label+1           \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probability2discreteOutput(ypred):\n",
    "    y_pred_d = []\n",
    "    for i in range(ypred.shape[0]):\n",
    "        y_pred_d.append(np.argmax(ypred[i]))\n",
    "    y_pred_d = np.asarray(y_pred_d)\n",
    "    return y_pred_d.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading breeds from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_LABEL)\n",
    "breeds = df_train.breed.unique()\n",
    "breeds = np.sort(breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "TRAIN_SET_DIR, \n",
    "target_size=(300, 300),\n",
    "batch_size=batch_size,#default = 32\n",
    "classes = breeds.tolist(),\n",
    "class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "VAL_SET_DIR,target_size=(300, 300),\n",
    "batch_size=batch_size,\n",
    "classes = breeds.tolist(),\n",
    "class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "TEST_SET_DIR,target_size=(300, 300),\n",
    "batch_size=batch_size,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning (InceptionV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_base = InceptionV3(weights='imagenet', include_top=False,input_shape=(300, 300, 3))\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu',input_shape=(300, 300, 3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(120, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto') \n",
    "callbackscallbac  = [early_stopping, PlotLossesKeras(), ModelCheckpoint('transfer_learningIN_1.h5', monitor='val_acc', save_best_only=True)]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer=\"adam\",\n",
    "metrics=['acc'])\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "train_generator,\n",
    "callbacks= callbackscallbac,\n",
    "steps_per_epoch=6547//batch_size,#size of the dataset divided by the size of the batch\n",
    "epochs=20,\n",
    "validation_data=validation_generator,\n",
    "validation_steps=1580//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('transfer_learningIN_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation: accuracy, error (log loss), and f1-score (average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 120\n",
    "size_img = 300\n",
    "size_test_set = 2095 \n",
    "test_features, test_labels = read_images(TEST_SET_DIR, size_test_set , size_img) # reading test features\n",
    "\n",
    "test_features = test_features.reshape(size_test_set , 300,300,3)\n",
    "test_labels = test_labels.reshape(size_test_set )\n",
    "test_labels = test_labels.astype(int)\n",
    "\n",
    "pred = model.predict(test_features)\n",
    "ypred = probability2discreteOutput(pred)#converting output to discrete label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_pred = hot_enconding(ypred, n_classes)\n",
    "encoded_true = hot_enconding(test_labels, n_classes)\n",
    "acc = accuracy_score(test_labels, ypred)\n",
    "loss = log_loss(encoded_true, pred, eps=1e-15)\n",
    "f1_sc = f1_score(test_labels, ypred, average='micro')\n",
    "print(\"acc:\",acc,\"error:\",loss,\"f1-score:\",f1_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_elem = test_generator.next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_breeds = dict(zip(breeds, range(breeds.shape[0])))\n",
    "data_batch = batch_elem[0]\n",
    "labels_batch = batch_elem[1]\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "#from https://matplotlib.org/2.0.2/mpl_toolkits/axes_grid/users/overview.html\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 5),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.04,  # pad between axes in inch.\n",
    "                 )\n",
    "font = {'family': 'serif',\n",
    "        'size': 14,\n",
    "        }\n",
    "for i in range(10):\n",
    "    ax = grid[i]\n",
    "    data = np.copy(data_batch[i])\n",
    "    label = labels_batch[i]\n",
    "    label_breed = np.argmax(label)\n",
    "    \n",
    "    x = np.expand_dims(data, axis=0)\n",
    "                \n",
    "    pred = model.predict(x)\n",
    "    label_pred = np.argmax(pred)\n",
    "    ax.text(10, 250, 'Label: %s' % (breeds[label_breed]),  fontdict=font, color='b', backgroundcolor='w', alpha=0.8)\n",
    "    ax.text(10, 280, 'Pred: %s' % (breeds[label_pred]),  fontdict=font, color='r', backgroundcolor='w', alpha=0.8)\n",
    "    ax.imshow(data)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Wrong Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_img = 300\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 5),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.04,  # pad between axes in inch.\n",
    "                 )\n",
    "font = {'family': 'serif',\n",
    "        'size': 14,\n",
    "        }\n",
    "ind = 0\n",
    "for root, dirs, files in os.walk(VAL_SET_DIR):\n",
    "        for dirname in dirs:\n",
    "            filelist = os.listdir(VAL_SET_DIR+'\\\\'+dirname)\n",
    "            filelist = np.asarray(filelist)\n",
    "            for filename in filelist:\n",
    "                if ind == 10:\n",
    "                    break\n",
    "                img_path = VAL_SET_DIR+'\\\\'+dirname+'\\\\'+filename\n",
    "                img = image.load_img(img_path, target_size=(size_img, size_img))\n",
    "                \n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "                \n",
    "                pred = model.predict(x)\n",
    "                label_pred = np.argmax(pred)\n",
    "                \n",
    "                if breeds[label_pred] != dirname:\n",
    "                    ax = grid[ind]\n",
    "                    #print(img_path)\n",
    "                    ax.text(10, 250, 'Label: %s' % dirname,  fontdict=font, color='b', backgroundcolor='w', alpha=0.8)\n",
    "                    ax.text(10, 280, 'Pred: %s' % (breeds[label_pred]),  fontdict=font, color='r', backgroundcolor='w', alpha=0.8)\n",
    "                    ax.imshow(img)\n",
    "                    ind = ind+1\n",
    "                    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypred = np.zeros([10357,120])#size of test set and number of classes\n",
    "filelist = os.listdir(TEST_DIR)\n",
    "filelist = np.asarray(filelist)\n",
    "i = 0\n",
    "diff = 0\n",
    "size_img = 300\n",
    "for filename in tqdm(filelist):\n",
    "    img_path = TEST_DIR+'\\\\'+filename\n",
    "    img = image.load_img(img_path, target_size=(size_img, size_img))\n",
    "                \n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    pred = model.predict(x)\n",
    "    ypred[i,:] = pred\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "for i in range(filelist.shape[0]):\n",
    "    name = filelist[i]\n",
    "    name = name[:len(name)-4]\n",
    "    ids.append(name)\n",
    "ids = np.asarray(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(ypred, columns = breeds)\n",
    "df_sub.insert(0, 'id', ids)\n",
    "df_sub.to_csv('architecture1.csv', index=False)\n",
    "print (df_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
